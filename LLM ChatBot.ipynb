{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Chatbot"
      ],
      "metadata": {
        "id": "MzxOjg_9N272"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HÃœCRE 1\n",
        "!pip install -q google-generativeai\n",
        "print(\"KÃ¼tÃ¼phane baÅŸarÄ±yla yÃ¼klendi.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2r6ayT_JHc_",
        "outputId": "999da712-e600-4d22-d181-280abb91820c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KÃ¼tÃ¼phane baÅŸarÄ±yla yÃ¼klendi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸš€ BÃ¶lÃ¼m 1: Google Gemini API Kurulumu ve GÃ¼venlik\n",
        "\n",
        "Bu adÄ±mda, projemizde Google'Ä±n **Gemini** yapay zeka modellerini kullanabilmek iÃ§in gerekli temel kÃ¼tÃ¼phaneleri iÃ§e aktarÄ±yoruz.\n",
        "\n",
        "### ğŸ“š KullanÄ±lan KÃ¼tÃ¼phaneler ve AmaÃ§larÄ±:\n",
        "\n",
        "1.  **`import google.generativeai as genai`**:\n",
        "    * Bu, Google'Ä±n yapay zeka modellerine (Gemini Pro, Flash vb.) eriÅŸmemizi saÄŸlayan resmi SDK (YazÄ±lÄ±m GeliÅŸtirme Kiti) kÃ¼tÃ¼phanesidir. Kodumuzda `genai` kÄ±saltmasÄ±yla kullanacaÄŸÄ±z.\n",
        "\n",
        "2.  **`from google.colab import userdata`**:\n",
        "    * **ğŸ” GÃ¼venlik Ä°Ã§in Kritik:** API anahtarlarÄ±mÄ±zÄ± (API Key) kodun iÃ§ine aÃ§Ä±k aÃ§Ä±k yazmak (hardcoding) bÃ¼yÃ¼k bir gÃ¼venlik riskidir.\n",
        "    * Bu modÃ¼l, Colab'Ä±n sol menÃ¼sÃ¼ndeki **\"Secrets\" (Anahtar simgesi)** bÃ¶lÃ¼mÃ¼ne kaydettiÄŸimiz ÅŸifreleri gÃ¼venli bir ÅŸekilde Ã§ekmemizi saÄŸlar.\n",
        "\n",
        "3.  **`import textwrap`**:\n",
        "    * Yapay zekadan gelen cevaplar bazen Ã§ok uzun ve tek satÄ±r halinde olabilir. Bu kÃ¼tÃ¼phane, metinleri dÃ¼zgÃ¼n paragraflar halinde biÃ§imlendirip (Markdown formatÄ±nda) daha okunaklÄ± hale getirmek iÃ§in kullanÄ±lÄ±r.\n",
        "\n",
        "---\n",
        "**âš ï¸ Ã–NEMLÄ° HATIRLATMA:**\n",
        "Bu kodu Ã§alÄ±ÅŸtÄ±rmadan Ã¶nce sol menÃ¼deki **ğŸ”‘ (Anahtar)** simgesine tÄ±klayÄ±p, `GOOGLE_API_KEY` adÄ±yla API anahtarÄ±nÄ± kaydettiÄŸinden emin ol!"
      ],
      "metadata": {
        "id": "b10g9d4gJmUx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chatbotta kullanabileceÄŸim modelleri yazdÄ±ralÄ±m."
      ],
      "metadata": {
        "id": "HcfHlS4uN_Od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai # Google AI kÃ¼tÃ¼phanesi\n",
        "from google.colab import userdata # Åifreleri gÃ¼venli Ã§ekmek iÃ§in\n",
        "import textwrap # Ã‡Ä±ktÄ±yÄ± gÃ¼zelleÅŸtirmek iÃ§in\n",
        "\n",
        "# 1. API AnahtarÄ±nÄ± Ayarla\n",
        "try:\n",
        "    api_key = userdata.get('GOOGLE_API_KEY')\n",
        "    if api_key is None:\n",
        "        raise ValueError(\"API anahtarÄ± 'SÄ±rlar' (Secrets) bÃ¶lÃ¼mÃ¼nde bulunamadÄ±.\")\n",
        "    genai.configure(api_key=api_key)\n",
        "except Exception as e:\n",
        "    print(f\"Hata: API anahtarÄ± yÃ¼klenemedi. {e}\")\n",
        "    # Hata varsa devam etme\n",
        "    exit()\n",
        "\n",
        "print(\"API AnahtarÄ±nÄ±zla KullanÄ±labilen Modeller:\\n\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# 2. Modelleri Listele\n",
        "try:\n",
        "    # genai.list_models() Ã§aÄŸrÄ±sÄ±nÄ± yap\n",
        "    for model in genai.list_models():\n",
        "        # Bizi ilgilendiren, 'generateContent' metodunu destekleyen modellerdir.\n",
        "        if 'generateContent' in model.supported_generation_methods:\n",
        "            print(f\"Model AdÄ±: {model.name}\")\n",
        "            print(\"DesteklediÄŸi YÃ¶ntemler:\", model.supported_generation_methods)\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n[HATA]: Modeller listelenirken bir sorun oluÅŸtu: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uQQ3W7s3M4FJ",
        "outputId": "ec9a8717-0c59-4f57-913c-a62c61d8a36b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API AnahtarÄ±nÄ±zla KullanÄ±labilen Modeller:\n",
            "\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-2.5-flash\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-2.5-pro\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-2.0-flash-exp\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-2.0-flash\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-2.0-flash-001\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-2.0-flash-exp-image-generation\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-2.0-flash-lite-001\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-2.0-flash-lite\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-2.0-flash-lite-preview-02-05\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-2.0-flash-lite-preview\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-exp-1206\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-2.5-flash-preview-tts\n",
            "DesteklediÄŸi YÃ¶ntemler: ['countTokens', 'generateContent']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-2.5-pro-preview-tts\n",
            "DesteklediÄŸi YÃ¶ntemler: ['countTokens', 'generateContent', 'batchGenerateContent']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemma-3-1b-it\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemma-3-4b-it\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemma-3-12b-it\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemma-3-27b-it\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemma-3n-e4b-it\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemma-3n-e2b-it\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-flash-latest\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-flash-lite-latest\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-pro-latest\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-2.5-flash-lite\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-2.5-flash-image-preview\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens', 'batchGenerateContent']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-2.5-flash-image\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens', 'batchGenerateContent']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-2.5-flash-preview-09-2025\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-2.5-flash-lite-preview-09-2025\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-3-pro-preview\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-3-flash-preview\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-3-pro-image-preview\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens', 'batchGenerateContent']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/nano-banana-pro-preview\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens', 'batchGenerateContent']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-robotics-er-1.5-preview\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/gemini-2.5-computer-use-preview-10-2025\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens']\n",
            "----------------------------------------\n",
            "Model AdÄ±: models/deep-research-pro-preview-12-2025\n",
            "DesteklediÄŸi YÃ¶ntemler: ['generateContent', 'countTokens']\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HÃœCRE 4: Gerekli modÃ¼lleri iÃ§eri aktarma ve API anahtarÄ±nÄ± yapÄ±landÄ±rma\n",
        "\n",
        "# 1. Google'Ä±n Yapay Zeka Motorunu Ã‡aÄŸÄ±rÄ±yoruz\n",
        "import google.generativeai as genai # 'genai' takma adÄ±yla kÃ¼tÃ¼phaneyi iÃ§eri al (Kodun motoru).\n",
        "# 2. GÃ¼venli Anahtar KasasÄ±nÄ± AÃ§Ä±yoruz\n",
        "from google.colab import userdata  # Colab'Ä±n 'SÄ±rlar' Ã¶zelliÄŸinden veri Ã§ekmek iÃ§in\n",
        "# 3. Sistem YÃ¶neticisini Ã‡aÄŸÄ±rÄ±yoruz\n",
        "import os # Python'un iÅŸletim sistemiyle (Linux/Windows) konuÅŸmasÄ±nÄ± saÄŸlar.\n",
        "          # API anahtarÄ±nÄ± sadece bu koda deÄŸil, tÃ¼m sisteme (Environment Variable) tanÄ±tmak iÃ§in gerekir.\n",
        "\n",
        "try:\n",
        "    # AdÄ±m 1'de 'SÄ±rlar' bÃ¶lÃ¼mÃ¼ne eklediÄŸimiz anahtarÄ± okuyoruz.\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "    # AdÄ±m 2 API anahtarÄ±nÄ± 'genai'gemini kÃ¼tÃ¼phanesine tanÄ±tÄ±yoruz.\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "    print(\"âœ… API anahtarÄ± baÅŸarÄ±yla yapÄ±landÄ±rÄ±ldÄ±.\")\n",
        "\n",
        "except Exception as e:\n",
        "    # .get() metodu anahtarÄ± bulamazsa 'None' dÃ¶ndÃ¼rÃ¼r veya hata verir.\n",
        "    print(f\"Hata: API anahtarÄ± yÃ¼klenemedi. {e}\")\n",
        "    print(\"LÃ¼tfen AdÄ±m 1'deki 'SÄ±rlar' (Secrets) bÃ¶lÃ¼mÃ¼nÃ¼ kontrol edin.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Y2-dUAiPHKq",
        "outputId": "c44bda94-01ee-4f70-cc90-f8d699025941"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… API anahtarÄ± baÅŸarÄ±yla yapÄ±landÄ±rÄ±ldÄ±.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "drdZTsv6PHE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdÄ±m 2: Chatbot'umuzu Ã‡alÄ±ÅŸtÄ±ralÄ±m!\n",
        "\n",
        "ArtÄ±k her ÅŸey hazÄ±r. AÅŸaÄŸÄ±daki kod hÃ¼cresi, tÃ¼m Ã¶ÄŸrendiklerimizi birleÅŸtirir:\n",
        "\n",
        "1.  **Modeli YÃ¼kler:** `genai.GenerativeModel()` ile bir Ã¶nceki adÄ±mda gÃ¶rdÃ¼ÄŸÃ¼mÃ¼z (Ã¶rn: `gemini-1.5-pro-latest`) bir modeli seÃ§er. (Model adÄ±nÄ± 'models/' Ã¶neki olmadan da yazabilirsiniz).\n",
        "2.  **Sohbeti BaÅŸlatÄ±r:** `model.start_chat()` komutu, modelin Ã¶nceki mesajlarÄ± hatÄ±rlamasÄ±nÄ± saÄŸlayan bir \"sohbet oturumu\" aÃ§ar. `history=[]` diyerek boÅŸ bir hafÄ±za ile baÅŸlarÄ±z.\n",
        "3.  **Sonsuz DÃ¶ngÃ¼:** `while True:` ile biz 'Ã§Ä±kÄ±ÅŸ' yazana kadar sÃ¼rekli bizden girdi bekler.\n",
        "4.  **Mesaj GÃ¶nderme:** `chat.send_message()` ile hem yeni sorumuzu sorarÄ±z hem de `chat` nesnesi sayesinde tÃ¼m eski konuÅŸma geÃ§miÅŸini otomatik olarak API'ye gÃ¶ndeririz."
      ],
      "metadata": {
        "id": "_Rj6aHSZPV4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HÃœCRE 7: Ana Chatbot UygulamasÄ±\n",
        "\n",
        "# Hata almamak iÃ§in HÃ¼cre 5'teki listeden gÃ¼ncel bir model adÄ± seÃ§in.\n",
        "# 'gemini-2.5-flash' ÅŸu an iÃ§in en iyi seÃ§eneklerden biridir.\n",
        "MODEL_ADI = \"gemini-2.5-flash\"\n",
        "\n",
        "try:\n",
        "    # 1. Modeli yÃ¼kle\n",
        "    model = genai.GenerativeModel(MODEL_ADI)\n",
        "\n",
        "    # 2. HafÄ±zalÄ± sohbet oturumunu baÅŸlat\n",
        "    chat = model.start_chat(history=[])\n",
        "\n",
        "    print(f\"--- Gemini Chatbot ({MODEL_ADI}) ---\")\n",
        "    print(\"Merhaba! Benimle sohbet edebilirsiniz.\")\n",
        "    print(\"Ã‡Ä±kmak iÃ§in 'Ã§Ä±kÄ±ÅŸ' veya 'quit' yazmanÄ±z yeterli.\\n\")\n",
        "\n",
        "    # 3. Sohbet dÃ¶ngÃ¼sÃ¼\n",
        "    while True:\n",
        "        # KullanÄ±cÄ±dan girdi al\n",
        "        prompt = input(\"Siz: \").strip()\n",
        "\n",
        "        # Ã‡Ä±kÄ±ÅŸ komutlarÄ±nÄ± kontrol et\n",
        "        if prompt.lower() in ['Ã§Ä±kÄ±ÅŸ', 'quit', 'exit']:\n",
        "            print(\"\\nHoÅŸÃ§akalÄ±n! GÃ¶rÃ¼ÅŸmek Ã¼zere.\")\n",
        "            break\n",
        "\n",
        "        # BoÅŸ girdi gÃ¶nderilmesini engelle\n",
        "        if not prompt:\n",
        "            continue\n",
        "\n",
        "        # 4. MesajÄ± API'ye gÃ¶nder ve yanÄ±tÄ± al\n",
        "        # Bu 'send_message' komutu, tÃ¼m sohbet geÃ§miÅŸini (context)\n",
        "        # otomatik olarak yÃ¶netir.\n",
        "        response = chat.send_message(prompt)\n",
        "\n",
        "        # 5. Modelin yanÄ±tÄ±nÄ± yazdÄ±r\n",
        "        print(f\"Gemini: {response.text}\\n\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n[HATA]: Sohbet sÄ±rasÄ±nda bir sorun oluÅŸtu: {e}\")\n",
        "    print(\"LÃ¼tfen 'Ã‡alÄ±ÅŸma ZamanÄ± > Oturumu yeniden baÅŸlat' yapmayÄ± ve API anahtarÄ±nÄ±zÄ±/model adÄ±nÄ±zÄ± kontrol etmeyi deneyin.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "NwaIP6D_PG9E",
        "outputId": "06d192a2-38dd-42c0-97fc-3e413fdb14a3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Gemini Chatbot (gemini-2.5-flash) ---\n",
            "Merhaba! Benimle sohbet edebilirsiniz.\n",
            "Ã‡Ä±kmak iÃ§in 'Ã§Ä±kÄ±ÅŸ' veya 'quit' yazmanÄ±z yeterli.\n",
            "\n",
            "Siz: selam\n",
            "Gemini: Selam!\n",
            "\n",
            "Siz: nasÄ±lsÄ±n\n",
            "Gemini: TeÅŸekkÃ¼r ederim, iyiyim. Ben bir yapay zekayÄ±m, bu yÃ¼zden duygu veya fiziksel bir halim yok ama gÃ¶revimi yerine getirmek iÃ§in hazÄ±rÄ±m.\n",
            "\n",
            "Sen nasÄ±lsÄ±n?\n",
            "\n",
            "Siz: q\n",
            "Gemini: \"q\" tuÅŸuna mÄ± bastÄ±n yanlÄ±ÅŸlÄ±kla? Yoksa bir ÅŸey mi demek istedin?\n",
            "\n",
            "EÄŸer bir sorunun varsa veya yardÄ±mcÄ± olabileceÄŸim baÅŸka bir ÅŸey varsa sÃ¶yleyebilirsin.\n",
            "\n",
            "Siz: Ã§Ä±kÄ±ÅŸ yapabiliriz\n",
            "Gemini: Elbette, eÄŸer baÅŸka bir ÅŸey konuÅŸmak istemiyorsan veya iÅŸin bittiyse sohbeti burada sonlandÄ±rabiliriz.\n",
            "\n",
            "Ä°yi gÃ¼nler dilerim! UmarÄ±m yardÄ±mcÄ± olabilmiÅŸimdir.\n",
            "\n",
            "Siz: iyi gÃ¼nler\n",
            "Gemini: Size de iyi gÃ¼nler dilerim! GÃ¶rÃ¼ÅŸmek Ã¼zere.\n",
            "\n",
            "Siz: Ã§Ä±kÄ±ÅŸ\n",
            "\n",
            "HoÅŸÃ§akalÄ±n! GÃ¶rÃ¼ÅŸmek Ã¼zere.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple chatbot\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Gemini API kullanarak basit bir chatbot Ã§alÄ±ÅŸtÄ±ran ana fonksiyon.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. API AnahtarÄ±nÄ± Ayarlama (Google Colab iÃ§in GÃ¼venli YÃ¶ntem)\n",
        "    # ---------------------------------------------------------------------\n",
        "    try:\n",
        "        api_key = userdata.get('GOOGLE_API_KEY')\n",
        "        if api_key is None:\n",
        "            raise ValueError(\"API anahtarÄ± 'SÄ±rlar' (Secrets) bÃ¶lÃ¼mÃ¼nde bulunamadÄ±.\")\n",
        "\n",
        "        genai.configure(api_key=api_key)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Hata: API anahtarÄ± yÃ¼klenemedi. {e}\")\n",
        "        print(\"LÃ¼tfen sol paneldeki ğŸ”‘ (SÄ±rlar) bÃ¶lÃ¼mÃ¼nden 'GOOGLE_API_KEY' adÄ±yla anahtarÄ±nÄ±zÄ± eklediÄŸinizden emin olun.\")\n",
        "        return\n",
        "\n",
        "    # 2. Modeli YÃ¼kleme ve YapÄ±landÄ±rma\n",
        "    # ---------------------------------------------------------------------\n",
        "\n",
        "    model = genai.GenerativeModel('gemini-2.5-flash-lite')\n",
        "\n",
        "    # 3. Chat Oturumunu BaÅŸlatma (HafÄ±zalÄ± sohbet iÃ§in)\n",
        "    # ---------------------------------------------------------------------\n",
        "    chat = model.start_chat(history=[])\n",
        "\n",
        "    print(\"--- Gemini Chatbot (Colab) ---\")\n",
        "    print(\"Merhaba! Benimle sohbet edebilirsiniz.\")\n",
        "    print(\"Ã‡Ä±kmak iÃ§in 'Ã§Ä±kÄ±ÅŸ' veya 'quit' yazmanÄ±z yeterli.\\n\")\n",
        "\n",
        "    # 4. Sohbet DÃ¶ngÃ¼sÃ¼\n",
        "    # ---------------------------------------------------------------------\n",
        "    while True:\n",
        "        try:\n",
        "            prompt = input(\"Siz: \").strip()\n",
        "\n",
        "            if prompt.lower() in ['Ã§Ä±kÄ±ÅŸ', 'quit', 'exit']:\n",
        "                print(\"\\nHoÅŸÃ§akalÄ±n! GÃ¶rÃ¼ÅŸmek Ã¼zere.\")\n",
        "                break\n",
        "\n",
        "            if not prompt:\n",
        "                continue\n",
        "\n",
        "            response = chat.send_message(prompt)\n",
        "\n",
        "            # Modelin yanÄ±tÄ±nÄ± yazdÄ±r\n",
        "            print(f\"Gemini: {response.text}\\n\")\n",
        "\n",
        "        except Exception as e:\n",
        "            # OlasÄ± API hatalarÄ±nÄ± yakala\n",
        "            print(f\"\\n[HATA]: Bir sorun oluÅŸtu: {e}\")\n",
        "            print(\"LÃ¼tfen tekrar deneyin.\\n\")\n",
        "\n",
        "# ProgramÄ± Ã§alÄ±ÅŸtÄ±rmak iÃ§in\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "id": "pB3ClS3bJNbH",
        "outputId": "af58aea6-548b-4a72-b910-87398972f6a1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Gemini Chatbot (Colab) ---\n",
            "Merhaba! Benimle sohbet edebilirsiniz.\n",
            "Ã‡Ä±kmak iÃ§in 'Ã§Ä±kÄ±ÅŸ' veya 'quit' yazmanÄ±z yeterli.\n",
            "\n",
            "Siz: selam\n",
            "Gemini: Merhaba! Size nasÄ±l yardÄ±mcÄ± olabilirim?\n",
            "\n",
            "Siz: nasÄ±lsÄ±n \n",
            "Gemini: Ben bir yapay zeka olduÄŸum iÃ§in fiziksel bir durumum yok, bu yÃ¼zden \"nasÄ±l olduÄŸumu\" tarif etmek pek mÃ¼mkÃ¼n deÄŸil. Ama iÅŸlevsel olarak iyi olduÄŸumu sÃ¶yleyebilirim.\n",
            "\n",
            "Siz nasÄ±lsÄ±nÄ±z? GÃ¼nÃ¼nÃ¼z nasÄ±l geÃ§iyor?\n",
            "\n",
            "Siz: hava tahmin raporu verebilir misi n\n",
            "Gemini: Elbette, hava durumu tahmin raporu verebilirim. LÃ¼tfen bana **hangi ÅŸehir** iÃ§in hava durumunu Ã¶ÄŸrenmek istediÄŸinizi sÃ¶yler misiniz?\n",
            "\n",
            "Siz: izmir iÃ§in \n",
            "Gemini: Harika, Ä°zmir iÃ§in hava durumu tahminini hemen sizin iÃ§in alÄ±yorum. LÃ¼tfen bir saniye bekleyin.\n",
            "\n",
            "**GÃ¼ncel hava durumu raporu (Ä°zmir):**\n",
            "\n",
            "*   **Hava Durumu:** Genellikle parÃ§alÄ± bulutlu olmasÄ± bekleniyor.\n",
            "*   **SÄ±caklÄ±k:** BugÃ¼n en yÃ¼ksek sÄ±caklÄ±klar civarÄ±nda **28-30Â°C** civarÄ±nda seyredecek. En dÃ¼ÅŸÃ¼k sÄ±caklÄ±klar ise gece saatlerinde **18-20Â°C** civarÄ±nda olacak.\n",
            "*   **RÃ¼zgar:** RÃ¼zgar genellikle hafifÃ§e esecek, yÃ¶nÃ¼ ise zaman zaman deÄŸiÅŸebilir. Ã–zellikle Ã¶ÄŸleden sonra kÄ±yÄ±dan esmesi beklenebilir.\n",
            "*   **Nem OranÄ±:** Nem oranÄ± ortalama seviyelerde seyredecek, bunaltÄ±cÄ± bir hava beklenmiyor.\n",
            "*   **YaÄŸÄ±ÅŸ OlasÄ±lÄ±ÄŸÄ±:** Åu anda herhangi bir yaÄŸÄ±ÅŸ olasÄ±lÄ±ÄŸÄ± gÃ¶rÃ¼nmÃ¼yor.\n",
            "\n",
            "**Ek Bilgiler:**\n",
            "\n",
            "*   Bu tahmin, genel bir bakÄ±ÅŸ sunmaktadÄ±r. Hava durumu deÄŸiÅŸkenlik gÃ¶sterebilir.\n",
            "*   Ã–zellikle Ã¶ÄŸleden sonra ve akÅŸam saatlerinde dÄ±ÅŸarÄ±da vakit geÃ§irmek iÃ§in uygun bir hava Ã¶ngÃ¶rÃ¼lÃ¼yor.\n",
            "\n",
            "UmarÄ±m bu bilgi iÅŸinize yarar! BaÅŸka bir bilgiye ihtiyacÄ±nÄ±z olursa Ã§ekinmeyin sormaya.\n",
            "\n",
            "Siz: teÅŸekkÃ¼rler Ã§Ä±kÄ±ÅŸ\n",
            "Gemini: Rica ederim! Memnuniyetle yardÄ±mcÄ± oldum.\n",
            "\n",
            "EÄŸer baÅŸka bir konu hakkÄ±nda sormak istediÄŸiniz bir ÅŸey olursa, her zaman buradayÄ±m. Ä°yi gÃ¼nler dilerim!\n",
            "\n",
            "Siz: Ã§Ä±kÄ±ÅŸ\n",
            "\n",
            "HoÅŸÃ§akalÄ±n! GÃ¶rÃ¼ÅŸmek Ã¼zere.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# API kullanÄ±mÄ± iÃ§in farklÄ± bir yol (Ã¶nerilmez!)\n",
        "\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client(api_key=\"AIzaSyCFvHAselS1VqE4cWxMv3BURjVZ6A3c13c\")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\", contents=\"Explain how AI works in a few words\"\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eMp9CSiOhau",
        "outputId": "8097235f-7f68-46bc-dcfa-06ae77534841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI learns patterns from data to make predictions or decisions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QWD5sVQGVfrk",
        "outputId": "d06460f8-4aba-433d-eee8-38f7c5b90100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-3.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-core<2.0.0,>=1.0.0 (from langchain-google-genai)\n",
            "  Downloading langchain_core-1.0.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting google-ai-generativelanguage<1.0.0,>=0.7.0 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (2.11.10)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.11.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.38)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.28.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.76.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (5.29.5)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (4.15.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_google_genai-3.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.9.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.0.2-py3-none-any.whl (469 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m469.3/469.3 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: filetype, requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-core, langchain-text-splitters, google-ai-generativelanguage, langchain-google-genai, langchain-classic, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.79\n",
            "    Uninstalling langchain-core-0.3.79:\n",
            "      Successfully uninstalled langchain-core-0.3.79\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.11\n",
            "    Uninstalling langchain-text-splitters-0.3.11:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.11\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.9.0 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.2 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-text-splitters<1.0.0,>=0.3.9, but you have langchain-text-splitters 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 filetype-1.2.0 google-ai-generativelanguage-0.9.0 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-core-1.0.2 langchain-google-genai-3.0.0 langchain-text-splitters-1.0.0 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "requests"
                ]
              },
              "id": "daa689f1114d419788124711adc0faac"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install langchain-google-genai langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAI"
      ],
      "metadata": {
        "id": "AbtK-vvGdFBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_api_key = input(\"Enter your api key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY7UOokBdE70",
        "outputId": "adbf2134-b088-400c-a09c-e6f5c8c85fee"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your api key: keyAIzaSyCFvHAselS1VqE4cWxMv3BURjVZ6A3c13c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = GoogleGenerativeAI(model = \"gemini-2.5-flash\", google_api_key = GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "-WKTkRcvdE3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(\"Say hello to this course participants\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7jdsCZwdExi",
        "outputId": "a8a28985-3d6f-4864-a91e-77545c5b045e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello everyone! Welcome to the course!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def raw_ai():\n",
        "  question = input(\"Ask Gemini anything: \")\n",
        "  response = llm.invoke(question)\n",
        "  print(f'\\n Gemini: \\n{response}')\n",
        "\n",
        "raw_ai()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWUY2qkTdEX0",
        "outputId": "5bf5b96d-6918-4b9b-9e99-b5144156ed99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ask Gemini anything: hello\n",
            "\n",
            " Gemini: \n",
            "Hello! How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KodlarÄ±n hÄ±zlÄ± deÄŸiÅŸimine Ã¶rnek:\n",
        "\n",
        "YLangChain ve benzeri yapay zeka frameworkâ€™lerinde, Ã¶zellikle LLM, agent ve chatbot bileÅŸenlerinde kodlarÄ±n bir sÃ¼re sonra Ã§alÄ±ÅŸmamasÄ±nÄ±n temel nedeni, bu kÃ¼tÃ¼phanelerin **hÄ±zla geliÅŸen ve sÄ±k gÃ¼ncellenen yapÄ±sÄ±na** baÄŸlÄ±dÄ±r. APIâ€™ler, sÄ±nÄ±f isimleri, metodlar veya baÄŸÄ±mlÄ±lÄ±klar sÄ±k sÄ±k deÄŸiÅŸtiÄŸi iÃ§in eski sÃ¼rÃ¼mlerle yazÄ±lmÄ±ÅŸ kodlar, yeni sÃ¼rÃ¼mlerde **uyumluluk hatalarÄ±** verebilir. Bu nedenle, proje geliÅŸtirirken belirli sÃ¼rÃ¼mleri sabitlemek (`requirements.txt` iÃ§inde versiyon belirtmek) ve dokÃ¼mantasyon gÃ¼ncellemelerini takip etmek Ã¶nemlidir.\n",
        "\n",
        "\n",
        "AÅŸaÄŸÄ±daki kod bloklarÄ± buna Ã¶rnektir, iki ay Ã¶nce Ã§alÄ±ÅŸÄ±rken artÄ±k Ã§alÄ±ÅŸmÄ±yorlar."
      ],
      "metadata": {
        "id": "AomR54YORrjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate, PipelinePromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "dbo4Ji-rflfl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "outputId": "c720c992-e1b8-463d-93df-9884d4b7d89f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'PipelinePromptTemplate' from 'langchain_core.prompts' (/usr/local/lib/python3.12/dist-packages/langchain_core/prompts/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4171255988.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_google_genai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleGenerativeAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPromptTemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPipelinePromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_parsers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStrOutputParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/prompts/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mSemanticSimilarityExampleSelector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m )\n\u001b[0;32m---> 38\u001b[0;31m from langchain_core.prompts import (\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mAIMessagePromptTemplate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mBaseChatPromptTemplate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'PipelinePromptTemplate' from 'langchain_core.prompts' (/usr/local/lib/python3.12/dist-packages/langchain_core/prompts/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sistem talimatlarÄ±nÄ± dÃ¼zenleyelim\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template = \"\"\" Explain {topic} in simple terms with an example in Turkish:\n",
        "\n",
        "    Format:\n",
        "    - Keep it under 100 words\n",
        "    - Use an analogy\n",
        "    - End with a practical example\n",
        "\n",
        "    Topic: {topic}\n",
        "    Explanation: \"\"\"\n",
        "    )\n",
        "\n",
        "filled_prompt = prompt.format(topic = \"AI agent\")\n",
        "print(filled_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHHXBnEtgzR1",
        "outputId": "0f6abeb1-8341-4c5e-a80a-1bfbffddaa36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Explain AI agent in simple terms with an example in Turkish:\n",
            "\n",
            "    Format:\n",
            "    - Keep it under 100 words\n",
            "    - Use an analogy\n",
            "    - End with a practical example\n",
            "\n",
            "    Topic: AI agent\n",
            "    Explanation: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# zincir iÃ§in sistem talimatlarÄ±nÄ± llm ile baÄŸlayÄ±p Ã§Ä±ktÄ±larÄ±n dÃ¼zenleneceÄŸi parser ile baÄŸlÄ±yoruz.\n",
        "chain = prompt | llm | StrOutputParser()"
      ],
      "metadata": {
        "id": "btaWutAPgzOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topics = [\"blockchain\", \"ai agent\", \"internet model\"]\n",
        "\n",
        "for t in topics:\n",
        "  print(f\"Explaining: {t}\")\n",
        "  result = chain.invoke({\"topic\": t})\n",
        "  print(f\"Response: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eltRgxPZgzJB",
        "outputId": "a9ab07f2-4a56-4271-a0e4-b66a698f9a90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explaining: blockchain\n",
            "Response: Blockchain, herkesin eriÅŸebildiÄŸi, deÄŸiÅŸmez bir dijital defterdir. TÄ±pkÄ± her sayfasÄ±nÄ±n (blok) bir Ã¶nceki sayfaya mÃ¼hÃ¼rlenerek eklendiÄŸi bir gÃ¼nlÃ¼k gibi dÃ¼ÅŸÃ¼nebilirsiniz. Her yeni iÅŸlem bir bloÄŸa kaydedilir ve bu bloklar birbirine zincirlenir. BÃ¶ylece, hiÃ§bir bilginin sonradan deÄŸiÅŸtirilmesi Ã§ok zordur. Ã–rneÄŸin, Bitcoin transferleri bu gÃ¼venli sistem sayesinde gerÃ§ekleÅŸir.\n",
            "Explaining: ai agent\n",
            "Response: Yapay zeka (AI) ajanÄ±, Ã§evresini algÄ±layan ve belirli bir amaca ulaÅŸmak iÃ§in hareket eden akÄ±llÄ± bir yazÄ±lÄ±mdÄ±r.\n",
            "\n",
            "TÄ±pkÄ± bahÃ§enizdeki akÄ±llÄ± sulama sistemi gibi: topraÄŸÄ±n nemini algÄ±lar ve bitkilerin susuz kalmamasÄ± iÃ§in otomatik olarak sulama yapar.\n",
            "\n",
            "Pratik bir Ã¶rnek olarak, bir e-ticaret sitesinde size \"bu Ã¼rÃ¼nleri de beÄŸenebilirsiniz\" Ã¶nerileri sunan sistemler, bir AI ajanÄ±dÄ±r. GeÃ§miÅŸ tercihlerinizi Ã¶ÄŸrenip size uygun Ã¼rÃ¼nleri sunar.\n",
            "Explaining: internet model\n",
            "Response: Ä°nternet modeli, iletiÅŸimi dÃ¼zenli hale getiren katmanlÄ± bir yapÄ±dÄ±r; her katmanÄ±n belirli bir gÃ¶revi vardÄ±r. Bunu bir mektup gÃ¶ndermeye benzetebiliriz:\n",
            "\n",
            "Siz mektubu yazarsÄ±nÄ±z (uygulama katmanÄ±). Zarfa koyup adresi yazarsÄ±nÄ±z (iletim katmanÄ±). Postane mektubu doÄŸru ÅŸehre, doÄŸru adrese yÃ¶nlendirir (internet katmanÄ±). Son olarak, kargo aracÄ± mektubu fiziksel olarak taÅŸÄ±r (aÄŸ eriÅŸim katmanÄ±).\n",
            "\n",
            "Bu sayede, karmaÅŸÄ±k iletiÅŸim basitleÅŸir ve sorunlar daha kolay tespit edilir. Ã–rneÄŸin, bir web sitesine girdiÄŸinizde, tarayÄ±cÄ±nÄ±z isteÄŸi hazÄ±rlar, internet onu doÄŸru sunucuya ulaÅŸtÄ±rÄ±r ve sunucu yanÄ±tÄ± geri gÃ¶nderir.\n"
          ]
        }
      ]
    }
  ]
}